{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install uv"
      ],
      "metadata": {
        "id": "5IkPZlq7tOjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T14:35:52.371781Z",
          "iopub.status.busy": "2024-05-31T14:35:52.371493Z",
          "iopub.status.idle": "2024-05-31T14:36:07.115766Z",
          "shell.execute_reply": "2024-05-31T14:36:07.114783Z",
          "shell.execute_reply.started": "2024-05-31T14:35:52.371757Z"
        },
        "trusted": true,
        "id": "wIUaHF-dtGIS",
        "outputId": "90308d45-0f55-4843-bdce-f2a6a4983fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics==8.1.15\n",
            "  Downloading ultralytics-8.1.15-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (3.7.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (4.9.0.80)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (9.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (2.1.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (0.16.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (4.66.1)\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (5.9.3)\n",
            "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.1.15)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.1.15) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.15) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.1.15) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.1.15) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.15) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.15) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.15) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.15) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (4.9.0)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.15) (2024.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.15) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.15) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.15) (1.3.0)\n",
            "Downloading ultralytics-8.1.15-py3-none-any.whl (715 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m715.1/715.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.15\n"
          ]
        }
      ],
      "source": [
        "!!uv pip install --system  ultralytics==8.1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-30T16:53:12.551437Z",
          "iopub.status.busy": "2024-05-30T16:53:12.550496Z",
          "iopub.status.idle": "2024-05-30T16:53:26.277631Z",
          "shell.execute_reply": "2024-05-30T16:53:26.276277Z",
          "shell.execute_reply.started": "2024-05-30T16:53:12.551394Z"
        },
        "trusted": true,
        "id": "88oKFgk0tGIe"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T14:36:16.529541Z",
          "iopub.status.busy": "2024-05-31T14:36:16.529182Z",
          "iopub.status.idle": "2024-05-31T14:36:23.826367Z",
          "shell.execute_reply": "2024-05-31T14:36:23.825408Z",
          "shell.execute_reply.started": "2024-05-31T14:36:16.529509Z"
        },
        "trusted": true,
        "id": "OfVJPomHtGIf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Iterable\n",
        "import yaml\n",
        "\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "from plotly import subplots\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEXQC1uRtGIh"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/dataset\"\n",
        "!mkdir \"/content/output\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk6pgzC8tGIi"
      },
      "outputs": [],
      "source": [
        "import kaggle as kg\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'suryakeerthigubbala'\n",
        "os.environ['KAGGLE_KEY'] = 'a176794881faaed6485bde341f29d531'\n",
        "\n",
        "kg.api.authenticate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXJP0kSqtGIk"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d rijubera2000/poaching-and-animal-detection-dataset\n",
        "kg.api.dataset_download_files(dataset = \"rijubera2000/poaching-and-animal-detection-dataset\", path='/content/dataset', unzip=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T14:36:40.859435Z",
          "iopub.status.busy": "2024-05-31T14:36:40.858876Z",
          "iopub.status.idle": "2024-05-31T14:36:40.891698Z",
          "shell.execute_reply": "2024-05-31T14:36:40.890499Z",
          "shell.execute_reply.started": "2024-05-31T14:36:40.859405Z"
        },
        "trusted": true,
        "id": "8-5HT_AttGIn"
      },
      "outputs": [],
      "source": [
        "# DATASET_PATH = '/kaggle/input/poaching-and-animal-detection-dataset'  # Path to source dataset\n",
        "# MASTER_PATH = '/kaggle/working/' # Path where all outputs are stored (intermediate and final)\n",
        "DATASET_PATH = '/content/dataset'  # Path to source dataset\n",
        "MASTER_PATH = '/content/output' # Path where all outputs are stored (intermediate and final)\n",
        "DEBUG = False # Activete to run notebook faster\n",
        "CPU = False\n",
        "\n",
        "if not CPU:\n",
        "    assert torch.cuda.is_available(), 'CUDA not found!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T14:36:47.308273Z",
          "iopub.status.busy": "2024-05-31T14:36:47.307923Z",
          "iopub.status.idle": "2024-05-31T14:47:30.338291Z",
          "shell.execute_reply": "2024-05-31T14:47:30.337400Z",
          "shell.execute_reply.started": "2024-05-31T14:36:47.308245Z"
        },
        "trusted": true,
        "id": "ZMhs0x1CtGIp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from collections import defaultdict, Counter\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import cv2\n",
        "import yaml  # Ensure PyYAML is installed\n",
        "\n",
        "# Type aliases\n",
        "DatasetIndex = Dict[str, Dict[str, List[str]]]\n",
        "DatasetStats = Dict[str, int]\n",
        "\n",
        "# LookupTable class definition\n",
        "class LookupTable:\n",
        "    def __init__(self, add_unknown_token=True):\n",
        "        self.add_unknown_token = add_unknown_token\n",
        "        self.table = {}\n",
        "        self.inverse_table = {}\n",
        "        if add_unknown_token:\n",
        "            self.add('<unknown>')\n",
        "\n",
        "    def add(self, item):\n",
        "        if item not in self.table:\n",
        "            index = len(self.table)\n",
        "            self.table[item] = index\n",
        "            self.inverse_table[index] = item\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.add_unknown_token:\n",
        "            return self.table.get(item, self.table['<unknown>'])\n",
        "        return self.table[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.table)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.table)\n",
        "\n",
        "# AnimalToYOLODatasetAdapter class definition\n",
        "class AnimalToYOLODatasetAdapter:\n",
        "\n",
        "    def __init__(self, path: str, label_filter: Optional[List[str]] = None):\n",
        "        self._path = path\n",
        "        self._index, self.label_stats, self.split_stats, self.label_lookup, self._size = \\\n",
        "            self._index_dataset(path, label_filter)\n",
        "\n",
        "    @staticmethod\n",
        "    def _index_dataset(path: str, label_filter: Optional[List[str]] = None) \\\n",
        "        -> Tuple[DatasetIndex, DatasetStats, DatasetStats, LookupTable, int]:\n",
        "\n",
        "        index: DatasetIndex = defaultdict(dict)\n",
        "        label_stats: DatasetStats = Counter()\n",
        "        split_stats: DatasetStats = Counter()\n",
        "        lookup = LookupTable(add_unknown_token=False)\n",
        "        size = 0\n",
        "\n",
        "        splits = os.listdir(path)\n",
        "        for split in splits:\n",
        "            split_path = os.path.join(path, split)\n",
        "            if not os.path.isdir(split_path):\n",
        "                continue\n",
        "            labels = os.listdir(split_path)\n",
        "            for label in tqdm(labels, desc=f'Indexing {split}', unit='sample'):\n",
        "                if label_filter is not None and label not in label_filter:\n",
        "                    continue\n",
        "\n",
        "                label_path = os.path.join(split_path, label)\n",
        "                sample_ids = [Path(filename).stem for filename in os.listdir(label_path)\n",
        "                              if filename != 'Label' and (filename.endswith('.jpg') or filename.endswith('.jpeg'))]\n",
        "                annotations_path = os.path.join(label_path, 'Label')\n",
        "                if not os.path.exists(annotations_path):\n",
        "                    continue\n",
        "                annot_sample_ids = [Path(filename).stem for filename in os.listdir(annotations_path)\n",
        "                                    if filename.endswith('.txt')]\n",
        "                assert set(sample_ids) == set(annot_sample_ids), 'Image sample ids and annotation sample ids do not match'\n",
        "\n",
        "                # Update index, stats and lookup\n",
        "                index[split][label] = sample_ids\n",
        "\n",
        "                n_samples = len(sample_ids)\n",
        "                label_stats[label] += n_samples\n",
        "                split_stats[split] += n_samples\n",
        "                size += n_samples\n",
        "\n",
        "                lookup.add(label)\n",
        "\n",
        "        return dict(index), dict(label_stats), dict(split_stats), lookup, size\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._size\n",
        "\n",
        "    @property\n",
        "    def labels(self) -> List[str]:\n",
        "        return list(self.label_lookup)\n",
        "\n",
        "    @property\n",
        "    def n_labels(self) -> int:\n",
        "        return len(self.label_lookup)\n",
        "\n",
        "    def get_random_samples(self, n: int, split: str = 'train') -> List[Tuple[str, str, str]]:\n",
        "        split_index = self._index.get(split, {})\n",
        "        if not split_index:\n",
        "            raise ValueError(f'Split \"{split}\" not found in the dataset.')\n",
        "        label_names = self.labels\n",
        "\n",
        "        result: List[Tuple[str, str, str]] = []\n",
        "        for i in range(n):\n",
        "            label = random.choice(label_names)\n",
        "            sample_ids = split_index[label]\n",
        "            sample_id = random.choice(sample_ids)\n",
        "            result.append((split, label, sample_id))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_split_size(self, split: str) -> int:\n",
        "        if split not in self.split_stats:\n",
        "            raise ValueError(f'Split \"{split}\" not found in the dataset.')\n",
        "        return self.split_stats[split]\n",
        "\n",
        "    def get_image_path(self, split: str, label: str, sample_id: str) -> str:\n",
        "        for ext in ['.jpg', '.jpeg']:\n",
        "            image_path = os.path.join(self._path, split, label, f'{sample_id}{ext}')\n",
        "            if os.path.exists(image_path):\n",
        "                return image_path\n",
        "        raise FileNotFoundError(f'Image for sample id \"{sample_id}\" not found in {split}/{label}!')\n",
        "\n",
        "    def load_image(self, split: str, label: str, sample_id: str) -> str:\n",
        "        image_path = self.get_image_path(split, label, sample_id)\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f'Image \"{image_path}\" not found!')\n",
        "        return cv2.imread(image_path)\n",
        "\n",
        "    def get_annot_path(self, split: str, label: str, sample_id: str) -> str:\n",
        "        return os.path.join(self._path, split, label, 'Label', f'{sample_id}.txt')\n",
        "\n",
        "    def parse_annot(self, split: str, label: str, sample_id: str) -> List[Tuple[str, float, float, float, float]]:\n",
        "        annot_path = self.get_annot_path(split, label, sample_id)\n",
        "        with open(annot_path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "        annots: List[Tuple[str, float, float, float, float]] = []\n",
        "        for l in lines:\n",
        "            items = l.split()\n",
        "            if len(items) < 5:\n",
        "                print(f\"Skipping invalid annotation in {annot_path}: {l.strip()}\")\n",
        "                continue\n",
        "            label_name = ' '.join(items[:-4])\n",
        "            coords = [float(v) for v in items[-4:]]\n",
        "            annots.append((label_name, *coords))\n",
        "        return annots\n",
        "\n",
        "    def convert(self, path: str) -> None:\n",
        "        for split in self._index:\n",
        "            split_path = os.path.join(path, split)\n",
        "            images_path = os.path.join(split_path, 'images')\n",
        "            labels_path = os.path.join(split_path, 'labels')\n",
        "            Path(images_path).mkdir(parents=True, exist_ok=True)\n",
        "            Path(labels_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            for label, sample_ids in tqdm(self._index[split].items(), desc='Converting to Yolo format', total=len(self._index[split])):\n",
        "                assert len(sample_ids) == len(set(sample_ids))\n",
        "                for sample_id in sample_ids:\n",
        "                    image_path = self.get_image_path(split, label, sample_id)\n",
        "                    new_image_path = os.path.join(images_path, f'{sample_id}.jpg')\n",
        "                    annots = self.parse_annot(split, label, sample_id)\n",
        "                    new_annot_path = os.path.join(labels_path, f'{sample_id}.txt')\n",
        "\n",
        "                    # Debug statement to check the annotations\n",
        "                    print(f\"Annotations for {sample_id}: {annots}\")\n",
        "\n",
        "                    # Image needs to be loaded in order to read width and height\n",
        "                    # which are required for coordinate normalization\n",
        "                    image = self.load_image(split, label, sample_id)\n",
        "                    h, w, _ = image.shape\n",
        "\n",
        "                    # Conversion\n",
        "                    converted_annot: List[Tuple[int, float, float, float, float]] = []\n",
        "                    for label, x_min, y_min, x_max, y_max in annots:\n",
        "                        label_index = self.label_lookup[label]\n",
        "                        x_center = (x_min + x_max) / (2 * w)\n",
        "                        y_center = (y_min + y_max) / (2 * h)\n",
        "                        width = (x_max - x_min) / w\n",
        "                        height = (y_max - y_min) / h\n",
        "\n",
        "                        converted_annot.append((label_index, x_center, y_center, width, height))\n",
        "\n",
        "                    # Save data\n",
        "                    with open(new_annot_path, 'a', encoding='utf-8') as f:\n",
        "                        converted_annot_lines = [' '.join([str(v) for v in row]) for row in converted_annot]\n",
        "                        f.write('\\n'.join(converted_annot_lines))\n",
        "                        f.write('\\n')\n",
        "\n",
        "                    if not os.path.exists(new_image_path):\n",
        "                        shutil.copy(image_path, new_image_path)\n",
        "\n",
        "# Example usage:\n",
        "# Make sure to set the path and debug variables\n",
        "DATASET_PATH = '/content/dataset'\n",
        "MASTER_PATH = '/content/output'\n",
        "DEBUG = False\n",
        "\n",
        "adapter = AnimalToYOLODatasetAdapter(\n",
        "    path=DATASET_PATH,\n",
        "    label_filter=['Horse'] if DEBUG else None\n",
        ")\n",
        "\n",
        "print(f'Total number of samples in the dataset is {len(adapter)}.')\n",
        "print(f'Total number of classes in the dataset is {adapter.n_labels}.')\n",
        "try:\n",
        "    print(f'Train dataset size is {adapter.get_split_size(\"train\")} (images). Test dataset size is {adapter.get_split_size(\"test\")} (images)')\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "adapter.convert(MASTER_PATH)\n",
        "\n",
        "# Generate the YOLO config file\n",
        "class_names = list(adapter.label_lookup.table.keys())\n",
        "config = {\n",
        "    'path': MASTER_PATH,\n",
        "    'train': 'train/images',\n",
        "    'val': 'test/images',\n",
        "    'nc': len(class_names),  # Number of classes\n",
        "    'names': class_names\n",
        "}\n",
        "\n",
        "# Print the config\n",
        "print(config)\n",
        "\n",
        "# Define the path where you want to save the config.yaml file\n",
        "config_path = '/content/config.yaml'\n",
        "\n",
        "# Write the config dictionary to a YAML file\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f'Config file saved to {config_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-31T14:47:41.135396Z",
          "iopub.status.busy": "2024-05-31T14:47:41.135026Z",
          "iopub.status.idle": "2024-06-01T00:24:32.344873Z",
          "shell.execute_reply": "2024-06-01T00:24:32.343827Z",
          "shell.execute_reply.started": "2024-05-31T14:47:41.135367Z"
        },
        "trusted": true,
        "id": "Q7zKS06vtGIu"
      },
      "outputs": [],
      "source": [
        "# Load a pretrained YOLO model (recommended for training)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model using the processed dataset\n",
        "results = model.train(\n",
        "    data='config.yaml',\n",
        "    epochs=100 if not DEBUG else 1,\n",
        "    optimizer='Adam',\n",
        "    val=True,\n",
        "    batch=64,\n",
        "    imgsz=640,\n",
        "    device=[0] if not CPU else 'cpu',\n",
        "    lr0=0.001,\n",
        "    lrf=0.0005\n",
        ")\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "results = model.val()\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T01:00:10.916967Z",
          "iopub.status.busy": "2024-06-01T01:00:10.916515Z",
          "iopub.status.idle": "2024-06-01T01:00:13.333559Z",
          "shell.execute_reply": "2024-06-01T01:00:13.332430Z",
          "shell.execute_reply.started": "2024-06-01T01:00:10.916916Z"
        },
        "trusted": true,
        "id": "7KGmRFhatGIw",
        "outputId": "1997707c-82cf-4834-afce-872c7e98d679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: kaggle/working/runs/ (stored 0%)\n",
            "  adding: kaggle/working/runs/detect/ (stored 0%)\n",
            "  adding: kaggle/working/runs/detect/train2/ (stored 0%)\n",
            "  adding: kaggle/working/runs/detect/train2/PR_curve.png (deflated 7%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch0_pred.jpg (deflated 12%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch2_labels.jpg (deflated 7%)\n",
            "  adding: kaggle/working/runs/detect/train2/confusion_matrix.png (deflated 16%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch1_labels.jpg (deflated 6%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch1_pred.jpg (deflated 6%)\n",
            "  adding: kaggle/working/runs/detect/train2/R_curve.png (deflated 9%)\n",
            "  adding: kaggle/working/runs/detect/train2/P_curve.png (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train2/confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: kaggle/working/runs/detect/train2/F1_curve.png (deflated 9%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch2_pred.jpg (deflated 6%)\n",
            "  adding: kaggle/working/runs/detect/train2/val_batch0_labels.jpg (deflated 12%)\n",
            "  adding: kaggle/working/runs/detect/train/ (stored 0%)\n",
            "  adding: kaggle/working/runs/detect/train/args.yaml (deflated 52%)\n",
            "  adding: kaggle/working/runs/detect/train/results.png (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train/PR_curve.png (deflated 7%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch0_pred.jpg (deflated 12%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch2.jpg (deflated 4%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch2_labels.jpg (deflated 11%)\n",
            "  adding: kaggle/working/runs/detect/train/confusion_matrix.png (deflated 17%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch1_labels.jpg (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch30510.jpg (deflated 12%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch1_pred.jpg (deflated 7%)\n",
            "  adding: kaggle/working/runs/detect/train/events.out.tfevents.1717166876.6a85e624364b.34.0 (deflated 89%)\n",
            "  adding: kaggle/working/runs/detect/train/R_curve.png (deflated 9%)\n",
            "  adding: kaggle/working/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: kaggle/working/runs/detect/train/weights/last.pt (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train/weights/best.pt (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch30512.jpg (deflated 10%)\n",
            "  adding: kaggle/working/runs/detect/train/P_curve.png (deflated 8%)\n",
            "  adding: kaggle/working/runs/detect/train/confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: kaggle/working/runs/detect/train/labels_correlogram.jpg (deflated 29%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch0.jpg (deflated 4%)\n",
            "  adding: kaggle/working/runs/detect/train/labels.jpg (deflated 20%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch1.jpg (deflated 4%)\n",
            "  adding: kaggle/working/runs/detect/train/F1_curve.png (deflated 9%)\n",
            "  adding: kaggle/working/runs/detect/train/results.csv (deflated 85%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch2_pred.jpg (deflated 10%)\n",
            "  adding: kaggle/working/runs/detect/train/train_batch30511.jpg (deflated 9%)\n",
            "  adding: kaggle/working/runs/detect/train/val_batch0_labels.jpg (deflated 12%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r results.zip /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T01:00:40.680740Z",
          "iopub.status.busy": "2024-06-01T01:00:40.679770Z",
          "iopub.status.idle": "2024-06-01T01:00:41.720973Z",
          "shell.execute_reply": "2024-06-01T01:00:41.719970Z",
          "shell.execute_reply.started": "2024-06-01T01:00:40.680698Z"
        },
        "trusted": true,
        "id": "mNebkbsRtGIy",
        "outputId": "11bdd98a-c0bd-42fd-b3c7-4870d4faadcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config.yaml  results.zip  runs\ttest  train  wandb  yolov8n.pt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T01:01:38.949607Z",
          "iopub.status.busy": "2024-06-01T01:01:38.948881Z",
          "iopub.status.idle": "2024-06-01T01:01:38.957208Z",
          "shell.execute_reply": "2024-06-01T01:01:38.956224Z",
          "shell.execute_reply.started": "2024-06-01T01:01:38.949569Z"
        },
        "trusted": true,
        "id": "SLlJQ9KhtGIy",
        "outputId": "5ca9b749-8717-437f-e706-d4613397d2e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<a href='results.zip' target='_blank'>results.zip</a><br>"
            ],
            "text/plain": [
              "/kaggle/working/results.zip"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink(r'results.zip')"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5117495,
          "sourceId": 8561533,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}